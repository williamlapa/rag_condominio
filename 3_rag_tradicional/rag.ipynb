{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe37963-1af6-44fc-a841-8e462443f5e6",
   "metadata": {},
   "source": [
    "## Usando RAG para Docs de condom√≠nio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba2779af-84ef-4227-9e9e-6eaf0df87e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG para Documentos de Condom√≠nio - Vers√£o Otimizada\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "\n",
    "# Imports LangChain\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c85082-e417-4708-9efe-81a5d55d1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. CONFIGURA√á√ÉO INICIAL\n",
    "# ============================================================================\n",
    "\n",
    "# Configura√ß√£o de modelos e diret√≥rios\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "DB_NAME = \"vector_db\"\n",
    "\n",
    "# Carregamento de vari√°veis de ambiente\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3dd496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. CARREGAMENTO E PROCESSAMENTO DE DOCUMENTOS\n",
    "# ============================================================================\n",
    "\n",
    "def load_documents():\n",
    "    \"\"\"Carrega documentos de forma organizada e com metadados apropriados\"\"\"\n",
    "    \n",
    "    BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../0_base_conhecimento\"))\n",
    "    CACHE_DIR = os.path.join(BASE_DIR, \"processed_docs_cache\")\n",
    "    \n",
    "    print(f\"üîç Verificando diret√≥rio: {CACHE_DIR}\")\n",
    "    \n",
    "    if not os.path.exists(CACHE_DIR):\n",
    "        print(f\"‚ùå Diret√≥rio n√£o encontrado: {CACHE_DIR}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"üìÅ Conte√∫do: {os.listdir(CACHE_DIR)}\")\n",
    "    \n",
    "    documents = []\n",
    "    text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "    \n",
    "    # Busca por subdiret√≥rios (tipos de documento)\n",
    "    for subfolder in os.listdir(CACHE_DIR):\n",
    "        subfolder_path = os.path.join(CACHE_DIR, subfolder)\n",
    "        \n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            continue\n",
    "            \n",
    "        doc_type = subfolder\n",
    "        print(f\"üìÑ Processando: {doc_type}\")\n",
    "        \n",
    "        # Carrega arquivos .txt\n",
    "        try:\n",
    "            txt_loader = DirectoryLoader(\n",
    "                subfolder_path, \n",
    "                glob=\"**/*.txt\", \n",
    "                loader_cls=TextLoader,\n",
    "                loader_kwargs=text_loader_kwargs,\n",
    "                recursive=True\n",
    "            )\n",
    "            txt_docs = txt_loader.load()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erro ao carregar TXT de {doc_type}: {e}\")\n",
    "            txt_docs = []\n",
    "        \n",
    "        # Carrega arquivos .docx\n",
    "        try:\n",
    "            docx_loader = DirectoryLoader(\n",
    "                subfolder_path,\n",
    "                glob=\"**/*.docx\",\n",
    "                loader_cls=UnstructuredFileLoader,\n",
    "                recursive=True\n",
    "            )\n",
    "            docx_docs = docx_loader.load()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erro ao carregar DOCX de {doc_type}: {e}\")\n",
    "            docx_docs = []\n",
    "        \n",
    "        # Processa e adiciona metadados\n",
    "        for doc in txt_docs + docx_docs:\n",
    "            # Limpa e padroniza o conte√∫do\n",
    "            content = str(doc.page_content).strip()\n",
    "            if len(content) < 50:  # Ignora documentos muito pequenos\n",
    "                continue\n",
    "                \n",
    "            # Cria documento com metadados enriquecidos\n",
    "            new_doc = Document(\n",
    "                page_content=content,\n",
    "                metadata={\n",
    "                    \"doc_type\": doc_type,\n",
    "                    \"source\": doc.metadata.get(\"source\", \"unknown\"),\n",
    "                    \"filename\": os.path.basename(doc.metadata.get(\"source\", \"unknown\"))\n",
    "                }\n",
    "            )\n",
    "            documents.append(new_doc)\n",
    "        \n",
    "        print(f\"‚úÖ {doc_type}: {len(txt_docs + docx_docs)} documentos carregados\")\n",
    "    \n",
    "    print(f\"üìä Total de documentos: {len(documents)}\")\n",
    "    return documents\n",
    "\n",
    "def create_chunks(documents):\n",
    "    \"\"\"Cria chunks otimizados para documentos de condom√≠nio\"\"\"\n",
    "    \n",
    "    if not documents:\n",
    "        print(\"‚ùå Nenhum documento para processar\")\n",
    "        return []\n",
    "    \n",
    "    # Splitter otimizado para documentos legais/administrativos\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,  # Menor para melhor precis√£o\n",
    "        chunk_overlap=150,  # Overlap maior para manter contexto\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    "        length_function=len\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # Adiciona informa√ß√µes extras aos metadados dos chunks\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk.metadata[\"chunk_id\"] = i\n",
    "        chunk.metadata[\"chunk_size\"] = len(chunk.page_content)\n",
    "    \n",
    "    print(f\"üîó Total de chunks criados: {len(chunks)}\")\n",
    "    print(f\"üìã Tipos de documento encontrados: {set(doc.metadata['doc_type'] for doc in documents)}\")\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca189274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. CRIA√á√ÉO DO VECTOR STORE\n",
    "# ============================================================================\n",
    "\n",
    "def create_vectorstore(chunks):\n",
    "    \"\"\"Cria vectorstore otimizado\"\"\"\n",
    "    \n",
    "    if not chunks:\n",
    "        return None\n",
    "    \n",
    "    # Embeddings com modelo mais recente\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    \n",
    "    # Remove database anterior se existir\n",
    "    if os.path.exists(DB_NAME):\n",
    "        import shutil\n",
    "        shutil.rmtree(DB_NAME)\n",
    "        print(f\"üóëÔ∏è Database anterior removido: {DB_NAME}\")\n",
    "    \n",
    "    # Cria novo vectorstore\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=DB_NAME,\n",
    "        collection_name=\"condo_docs\"\n",
    "    )\n",
    "    \n",
    "    count = vectorstore._collection.count()\n",
    "    print(f\"üíæ Vectorstore criado com {count:,} documentos\")\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e4d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. CONFIGURA√á√ÉO DO CHAT RAG\n",
    "# ============================================================================\n",
    "\n",
    "def setup_rag_chain(vectorstore):\n",
    "    \"\"\"Configura a cadeia RAG com prompt customizado\"\"\"\n",
    "    \n",
    "    # Prompt customizado para documentos de condom√≠nio\n",
    "    custom_prompt = PromptTemplate(\n",
    "        template=\"\"\"Voc√™ √© um assistente especializado em documentos de condom√≠nio. \n",
    "        Use as informa√ß√µes fornecidas para responder de forma precisa e detalhada.\n",
    "\n",
    "        Contexto dos documentos:\n",
    "        {context}\n",
    "\n",
    "        Hist√≥rico da conversa:\n",
    "        {chat_history}\n",
    "\n",
    "        Pergunta: {question}\n",
    "\n",
    "        Instru√ß√µes:\n",
    "        - Responda baseado APENAS nas informa√ß√µes dos documentos fornecidos\n",
    "        - Se n√£o encontrar a informa√ß√£o, diga claramente que n√£o est√° dispon√≠vel nos documentos\n",
    "        - Cite o tipo de documento quando relevante (ata, contrato, etc.)\n",
    "        - Seja preciso com datas, valores e nomes\n",
    "        - Use formata√ß√£o clara para listas e informa√ß√µes importantes\n",
    "\n",
    "        Resposta:\"\"\",\n",
    "        input_variables=[\"context\", \"chat_history\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    # LLM\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0.3,  # Baixa temperatura para respostas mais precisas\n",
    "        model_name=MODEL\n",
    "    )\n",
    "    \n",
    "    # Mem√≥ria\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history',\n",
    "        return_messages=True,\n",
    "        output_key='answer'\n",
    "    )\n",
    "    \n",
    "    # Retriever com configura√ß√µes otimizadas\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\n",
    "            \"k\": 10,  # N√∫mero de chunks a recuperar\n",
    "            \"fetch_k\": 20  # N√∫mero de chunks a considerar antes de filtrar\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Chain\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        memory=memory,\n",
    "        return_source_documents=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return conversation_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61157f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Iniciando processamento...\n",
      "üîç Verificando diret√≥rio: c:\\Users\\02392179425\\Desktop\\rag_condominio\\0_base_conhecimento\\processed_docs_cache\n",
      "üìÅ Conte√∫do: ['049b078c-b5bf-4d97-bdf7-a2fbd7c66f3b.txt', '065b78d0-c521-4ff9-9932-3825b4b82437.txt', '080a5ffd-2464-40f4-92c0-b4b07e45f617.txt', '2789187e-d466-448c-95ff-f7ff1250a5a4.txt', '280c2644-d328-40d5-bd2c-755a12df2a78.txt', '2ab34b5f-907f-4a18-b0d1-00b152a94df0.txt', '2d264460-0427-482b-ae8d-1c63b20fc53a.txt', '4ef8fafa-78b6-4f4e-8c81-6ca0132fe3b4.txt', '5f64b310-fb6b-412e-b295-96c52a2a1cf4.txt', '5f6bce90-49ed-4d61-858a-fba2f2e1bfe0.txt', '633681a6-5e09-4894-b648-7204c60baea2.txt', '65acae7c-a59f-4e10-8d41-22632869a150.txt', '6917e5df-e366-4198-98b0-1ee290786cb9.txt', '798a79eb-8cbc-4645-9610-474411733ed5.txt', '7cf9f6a5-99d3-4c15-9197-bfb22d2ea64e.txt', '874d4d25-d861-48a4-8060-b2c281d0ff20.txt', '8a71943b-ebd6-45a5-856b-5ead72b58d06.txt', '98e667e9-9dc1-4e00-a6fe-51fb7fa0b1a1.txt', '9c5d36c6-bda9-40df-a782-6f42537facf5.txt', '9c7408f2-660f-4f7d-8272-3e8b462be3ae.txt', '9d0b28a5-1c42-4db7-8106-9df09cd2764b.txt', 'a3ab79c5-52e6-43bd-8743-58a5714651b1.txt', 'ATA_22_04_2025.docx', 'cd0a0fe2-f556-4d41-8de8-06eb5b0e0230.txt', 'd2c0503c-1caa-4c0c-b7d3-56bb31064a58.txt', 'd648bb35-c0f2-4f1e-ae64-83408184cd47.txt', 'dbf86d04-be52-4e18-81f1-8363f6b313e7.txt', 'de470402-edbe-45ca-9e00-c4604382f55d.txt', 'df61199b-6199-471d-a952-219f17af1950.txt', 'e96e4dac-fc58-4346-a8cc-7f349b0e4458.txt', 'fa4323cb-3eae-4339-9357-ae5c84a233de.txt']\n",
      "üìä Total de documentos: 0\n",
      "‚ùå ERRO: Nenhum documento foi carregado!\n",
      "Verifique:\n",
      "1. Se o diret√≥rio '../0_base_conhecimento/processed_docs_cache' existe\n",
      "2. Se h√° arquivos .txt ou .docx nas subpastas\n",
      "3. Se os arquivos t√™m conte√∫do suficiente\n",
      "‚ùå Nenhum documento para processar\n",
      "‚ùå ERRO: Nenhum chunk foi criado!\n",
      "‚ùå ERRO: Falha na cria√ß√£o do vectorstore!\n",
      "‚ùå ERRO no teste do vectorstore: 'NoneType' object has no attribute 'similarity_search'\n",
      "‚ùå ERRO na configura√ß√£o do RAG: 'NoneType' object has no attribute 'as_retriever'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02392179425\\AppData\\Local\\Temp\\ipykernel_27192\\3604682758.py:39: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 5. EXECU√á√ÉO PRINCIPAL\n",
    "# ============================================================================\n",
    "\n",
    "# Carregamento e processamento\n",
    "print(\"üöÄ Iniciando processamento...\")\n",
    "\n",
    "# Passo 1: Carregar documentos\n",
    "documents = load_documents()\n",
    "if not documents:\n",
    "    print(\"‚ùå ERRO: Nenhum documento foi carregado!\")\n",
    "    print(\"Verifique:\")\n",
    "    print(\"1. Se o diret√≥rio '../0_base_conhecimento/processed_docs_cache' existe\")\n",
    "    print(\"2. Se h√° arquivos .txt ou .docx nas subpastas\")\n",
    "    print(\"3. Se os arquivos t√™m conte√∫do suficiente\")\n",
    "    exit()\n",
    "\n",
    "# Passo 2: Criar chunks\n",
    "chunks = create_chunks(documents)\n",
    "if not chunks:\n",
    "    print(\"‚ùå ERRO: Nenhum chunk foi criado!\")\n",
    "    exit()\n",
    "\n",
    "# Passo 3: Criar vectorstore\n",
    "vectorstore = create_vectorstore(chunks)\n",
    "if vectorstore is None:\n",
    "    print(\"‚ùå ERRO: Falha na cria√ß√£o do vectorstore!\")\n",
    "    exit()\n",
    "\n",
    "# Passo 4: Testar vectorstore\n",
    "try:\n",
    "    test_query = vectorstore.similarity_search(\"assembleia\", k=1)\n",
    "    print(f\"‚úÖ Teste do vectorstore: {len(test_query)} resultados encontrados\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO no teste do vectorstore: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Passo 5: Configura√ß√£o do RAG\n",
    "try:\n",
    "    conversation_chain = setup_rag_chain(vectorstore)\n",
    "    print(\"‚úÖ Sistema RAG configurado com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO na configura√ß√£o do RAG: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 6. TESTE COM PERGUNTAS EXEMPLO\n",
    "# ============================================================================\n",
    "\n",
    "def test_questions():\n",
    "    \"\"\"Testa o sistema com perguntas exemplo\"\"\"\n",
    "    \n",
    "    sample_questions = [\n",
    "        \"Quando ocorreu a √∫ltima assembleia registrada?\",\n",
    "        \"Quais s√£o os contratos ativos do condom√≠nio?\",\n",
    "        \"Qual o valor atual da taxa condominial?\",\n",
    "        \"Quem s√£o os membros do conselho fiscal?\",\n",
    "        \"Existe contrato de manuten√ß√£o de elevadores?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üß™ TESTANDO SISTEMA COM PERGUNTAS EXEMPLO\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, question in enumerate(sample_questions, 1):\n",
    "        print(f\"\\nüìù Pergunta {i}: {question}\")\n",
    "        try:\n",
    "            result = conversation_chain.invoke({\"question\": question})\n",
    "            answer = result['answer']\n",
    "            sources = result.get('source_documents', [])\n",
    "            \n",
    "            print(f\"üí¨ Resposta: {answer}\")\n",
    "            \n",
    "            if sources:\n",
    "                print(f\"üìÑ Fontes ({len(sources)}): \", end=\"\")\n",
    "                doc_types = [doc.metadata.get('doc_type', 'unknown') for doc in sources[:3]]\n",
    "                print(\", \".join(set(doc_types)))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro: {e}\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Executar teste\n",
    "test_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 7. INTERFACE GRADIO\n",
    "# ============================================================================\n",
    "\n",
    "def chat_function(message, history):\n",
    "    \"\"\"Fun√ß√£o de chat para Gradio\"\"\"\n",
    "    try:\n",
    "        result = conversation_chain.invoke({\"question\": message})\n",
    "        return result[\"answer\"]\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao processar pergunta: {str(e)}\"\n",
    "\n",
    "# Criar interface\n",
    "print(\"\\nüåê Iniciando interface Gradio...\")\n",
    "interface = gr.ChatInterface(\n",
    "    fn=chat_function,\n",
    "    type=\"messages\",\n",
    "    title=\"üè¢ Assistente de Condom√≠nio RAG\",\n",
    "    description=\"Fa√ßa perguntas sobre os documentos do condom√≠nio (atas, contratos, etc.)\",\n",
    "    examples=[\n",
    "        \"Quando foi a √∫ltima assembleia?\",\n",
    "        \"Quais contratos est√£o vigentes?\",\n",
    "        \"Qual o valor da taxa condominial?\",\n",
    "        \"Quem s√£o os s√≠ndicos atuais?\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Lan√ßar interface\n",
    "interface.launch(\n",
    "    inbrowser=True,\n",
    "    share=False,\n",
    "    server_name=\"127.0.0.1\",\n",
    "    server_port=7860\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
